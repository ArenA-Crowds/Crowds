{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-18232149d53a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0maffinity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0maffinity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_ktrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_ktrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdamping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffinity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precomputed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-18232149d53a>\u001b[0m in \u001b[0;36mbdist\u001b[0;34m(a, b, sigma, eps, th, lth, div)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017 Tampere University of Technology (TUT)\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n",
    "# of the Software, and to permit persons to whom the Software is furnished to do\n",
    "# so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# python script to cluster WLAN RSS fingerprint data with affinity projection\n",
    "# method and compute positioning error on test data\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# enter path to directory where data is stored\n",
    "path_to_database = 'F:/ArenaData/Fingerprinting'\n",
    "# choose algorithm 'km' for k-means and 'ap' for affinity propagation\n",
    "method = 'ap' # 'km'\n",
    "\n",
    "\n",
    "def load_data(path_to_data):\n",
    "\n",
    "    # training data\n",
    "    FILE_NAME_TRAIN_RSS = path_to_data + '/1478167720_9233432_trainingData.csv'\n",
    "    FILE_NAME_TRAIN_COORDS = path_to_data + '/1478167720_9233432_trainingData.csv'\n",
    "    # read training data\n",
    "    data_train = genfromtxt(FILE_NAME_TRAIN_RSS, delimiter=',')\n",
    "    data_train = data_train[1:, :]\n",
    "    X_train = data_train[:,0:520]\n",
    "    #labels_train = genfromtxt(FILE_NAME_TRAIN_COORDS, delimiter=',')\n",
    "    y_train = data_train[:,520:523]\n",
    "    y_train[:,2]*=3\n",
    "    X_train[X_train==100] = np.nan\n",
    "    phoneID_train = data_train[:,527]\n",
    "    timestamp_train = data_train[:,528]\n",
    "    floors_train = 3*data_train[:, 522]\n",
    "    \n",
    "    # test data\n",
    "    FILE_NAME_TEST_RSS = path_to_data + '/1478167721_0345678_validationData.csv'\n",
    "    FILE_NAME_TEST_COORDS = path_to_data + '/1478167721_0345678_validationData.csv'\n",
    "    # read test data\n",
    "    data_test = genfromtxt(FILE_NAME_TEST_RSS, delimiter=',')\n",
    "    datatest = data_test[1:,:]\n",
    "    #data_test = genfromtxt(FILE_NAME_TEST_COORDS, delimiter=',')\n",
    "    X_test = data_test[:,0:520]\n",
    "    y_test = data_test[:,520:523]\n",
    "    y_test[:,2]*=3\n",
    "    X_test[X_test==100] = np.nan\n",
    "    phoneID_test = data_test[:,527]\n",
    "    timestamp_test = data_test[:,528]\n",
    "    floors_test = 3*data_test[:, 522]\n",
    "    X_test[X_test==100] = np.nan\n",
    "    return (X_train, y_train, phoneID_train, timestamp_train, floors_train, X_test, y_test,phoneID_test,timestamp_test,floors_test )\n",
    "\n",
    "\n",
    "\n",
    "def distance(a, b):\n",
    "    return np.sqrt(np.sum(np.power(a-b, 2)))\n",
    "\n",
    "\n",
    "def bdist(a, b, sigma, eps, th, lth=-85, div=10):\n",
    "    diff = a - b\n",
    "\n",
    "    proba = 1/(np.sqrt(2*np.pi)*sigma)*np.exp( \\\n",
    "        -np.power(diff, 2)/(2.0*sigma**2))\n",
    "\n",
    "    proba[np.isnan(proba)] = eps\n",
    "    proba[proba < th] = eps\n",
    "    proba = np.log(proba)\n",
    "    if a.ndim == 2:\n",
    "        cost = np.sum(proba, axis=1)\n",
    "    else:\n",
    "        cost = np.sum(proba)\n",
    "\n",
    "    inv = np.zeros(a.shape[0])\n",
    "    for i in range(a.shape[0]):\n",
    "        aa = np.logical_and(~np.isnan(a[i]), np.isnan(b))\n",
    "        bb = np.logical_and(np.isnan(a[i]), ~np.isnan(b))\n",
    "\n",
    "        nfound = np.concatenate((a[i,aa], b[bb]))\n",
    "        for v in nfound[nfound > lth]:\n",
    "            inv[i] += v - lth\n",
    "\n",
    "    inv /= div\n",
    "    cost -= inv\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def cluster_subset_kmeans(clusters, labels, pos, X_test):\n",
    "    d = []\n",
    "    for i,c in enumerate(kmeans.cluster_centers_):\n",
    "        d.append(distance(pos[:2], c[:2]))\n",
    "\n",
    "    center = np.argmin(d)\n",
    "\n",
    "    return (ss[center], cs[center])\n",
    "\n",
    "\n",
    "def cluster_subset_affinityprop(clusters, labels, X_test):\n",
    "    subset = np.zeros(labels.shape[0]).astype(np.bool)\n",
    "\n",
    "    d = bdist(clusters, X_test, 5, 1e-3, 1e-25)\n",
    "    idx = np.argsort(d)[::-1]\n",
    "\n",
    "    cused = 0\n",
    "    for c in idx[:5]:\n",
    "        subset = np.logical_or(subset, c == labels)\n",
    "        cused += 1\n",
    "\n",
    "    return (subset, cused)\n",
    "\n",
    "\n",
    "def bayes_position(X_train, y_train, X_test, N, sigma, eps, th, lth, div, y_test):\n",
    "    diff = X_train - X_test\n",
    "\n",
    "    proba = 1/(np.sqrt(2*np.pi)*sigma)*np.exp( \\\n",
    "        -np.power(diff, 2)/(2.0*sigma**2))\n",
    "\n",
    "    proba[np.isnan(proba)] = eps\n",
    "    proba[proba < th] = eps\n",
    "    proba = np.log(proba)\n",
    "    cost = np.sum(proba, axis=1)\n",
    "\n",
    "    inv = np.zeros(X_train.shape[0])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        a = np.logical_and(~np.isnan(X_train[i]), np.isnan(X_test))\n",
    "        b = np.logical_and(np.isnan(X_train[i]), ~np.isnan(X_test))\n",
    "\n",
    "        nfound = np.concatenate((X_train[i,a], X_test[b]))\n",
    "        for v in nfound[nfound > lth]:\n",
    "            inv[i] += v - lth\n",
    "\n",
    "    inv /= div\n",
    "    cost -= inv\n",
    "\n",
    "    idx = np.argsort(cost)[::-1]\n",
    "\n",
    "    bias = 3\n",
    "    position = np.zeros(3)\n",
    "    N = min(N, y_train.shape[0])\n",
    "    for i in range(N):\n",
    "        weight = N-i\n",
    "        if i == 0:\n",
    "            weight += bias\n",
    "\n",
    "        position += weight*y_train[idx[i]]\n",
    "\n",
    "    position /= N*(N+1)/2+bias\n",
    "\n",
    "    return (np.array(position), np.mean(inv[idx[:20]]))\n",
    "\n",
    "\n",
    "def position_route(method, X_train, y_train, X_test, y_test, clusters, labels,\n",
    "                   N=5, sigma=5, eps=3e-4, th=1e-25, lth=-85, div=10):\n",
    "\n",
    "    error = []\n",
    "    error2D = []\n",
    "    fdetect = 0\n",
    "    y_pred = []\n",
    "    cused = []\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if i > 1:\n",
    "            if method=='km':\n",
    "                subset, c = cluster_subset_kmeans(clusters, labels, pos, X_test[i])\n",
    "                cused.append(c)\n",
    "            elif method=='ap':\n",
    "                subset, c = cluster_subset_affinityprop(clusters, labels, X_test[i])\n",
    "                cused.append(c)\n",
    "        else:\n",
    "            subset = np.ones(X_train.shape[0]).astype(np.bool)\n",
    "\n",
    "        if method=='km':\n",
    "            pos, q = bayes_position(X_train[subset], y_train[subset], X_test[i], N, sigma,\n",
    "                                    eps, th, lth, div, y_test[i])\n",
    "\n",
    "            if q > 50:\n",
    "                pos, _ = bayes_position(X_train, y_train, X_test[i], N, sigma,\n",
    "                                        eps, th, lth, div, y_test[i])\n",
    "        elif method=='ap':\n",
    "            pos, _ = bayes_position(X_train[subset], y_train[subset], X_test[i], N, sigma,\n",
    "                                    eps, th, lth, div, y_test[i])\n",
    "\n",
    "        pos[2] = floors[np.argmin(np.abs(floors-pos[2]))]\n",
    "\n",
    "        if i > 1:\n",
    "            y_pred.append(pos)\n",
    "            error.append(distance(y_test[i], y_pred[-1]))\n",
    "            fdetect += y_pred[-1][2] == y_test[i][2]\n",
    "            # 2D error only if floor was detected correctly\n",
    "            if y_pred[-1][2] == y_test[i][2]:\n",
    "                error2D.append(distance(y_test[i,0:2], np.array(y_pred[-1])[0:2]))\n",
    "\n",
    "    return (np.array(y_pred), np.array(error), np.array(error2D), fdetect, np.array(cused))\n",
    "\n",
    "tsum = 0\n",
    "\n",
    "# load data\n",
    "X_train, y_train, phoneID_train, timestamp_train, floors_train, X_test, y_test,phoneID_test,timestamp_test,floors_test  = load_data(path_to_database)\n",
    "\n",
    "# prepare data for processing\n",
    "ap_count = X_train.shape[1]\n",
    "floors = np.unique(floors_train)\n",
    "\n",
    "X_ktrain = X_train.copy()\n",
    "y_ktrain = y_train.copy()\n",
    "\n",
    "X_aux = X_ktrain.copy()\n",
    "X_aux[np.isnan(X_aux)] = 0\n",
    "\n",
    "M = X_ktrain.shape[1]\n",
    "corr = np.zeros((M,M))\n",
    "cth = 500\n",
    "keep = np.ones(M).astype(np.bool)\n",
    "for i in range(M):\n",
    "    for j in range(i,M):\n",
    "        if i != j:\n",
    "            diff = np.abs(X_aux[:,i] - X_aux[:,j])\n",
    "            corr[i,j] = corr[j,i] = np.sum(diff)\n",
    "        else:\n",
    "            corr[i,j] = cth\n",
    "\n",
    "    if keep[i] and np.sum(corr[i,:] < cth) > 0:\n",
    "        for p in np.where(corr[i,:] < cth)[0]:\n",
    "            keep[p] = False\n",
    "\n",
    "X_ktrain = X_ktrain[:,keep]\n",
    "X_test = X_test[:,keep]\n",
    "\n",
    "if method=='km':\n",
    "    C = 25\n",
    "\n",
    "    kmeans = KMeans(n_clusters=C, n_init=500, n_jobs=2, tol=1e-9)\n",
    "    labels = kmeans.fit_predict(y_ktrain)\n",
    "    clusters = kmeans.cluster_centers_\n",
    "\n",
    "    N = X_ktrain.shape[0]\n",
    "    aux = np.zeros((C,C))\n",
    "    for i in range(N):\n",
    "        dist = np.zeros(N)\n",
    "        for j in range(N):\n",
    "            dist[j] = distance(y_ktrain[i], y_ktrain[j])\n",
    "\n",
    "        idx = np.argsort(dist)\n",
    "\n",
    "        for p in np.where(labels[idx] != labels[i])[0]:\n",
    "            if dist[idx[p]] < 10:\n",
    "                aux[labels[i],labels[idx[p]]] += 1\n",
    "\n",
    "    ss = np.zeros((C,labels.size)).astype(np.bool)\n",
    "    cs = np.zeros(C)\n",
    "    rssl = []\n",
    "    rssc = []\n",
    "    for c in range(C):\n",
    "        aux[c,c] = 1\n",
    "\n",
    "        for i in np.where(aux[c] != 0)[0]:\n",
    "            ss[c] = np.logical_or(ss[c], labels == i)\n",
    "            cs[c] += 1\n",
    "\n",
    "elif method=='ap':\n",
    "    N = X_ktrain.shape[0]\n",
    "    affinity = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        affinity[i,:] = bdist(X_ktrain, X_ktrain[i], 5, 1e-3, 1e-25)\n",
    "\n",
    "    cluster = AffinityPropagation(damping=0.5, affinity='precomputed')\n",
    "    labels = cluster.fit_predict(affinity)\n",
    "    C = np.unique(labels).size\n",
    "    clusters = X_ktrain[cluster.cluster_centers_indices_]\n",
    "\n",
    "else:\n",
    "    print('Unknown method. Please choose either \"km\" or \"ap\".')\n",
    "    quit()\n",
    "\n",
    "\n",
    "t = time.clock()\n",
    "# estimate positions for test data\n",
    "y, error3D, error2D, fdetect, cused = position_route(method, X_ktrain,\n",
    "            y_ktrain, X_test, y_test, clusters, labels, N=5, eps=1e-3)\n",
    "tsum += time.clock() - t\n",
    "\n",
    "print('Mean positioning error 2D: \\t%.3lf m' % np.mean(error2D))\n",
    "print('Mean positioning error 3D: \\t%.3lf m' % np.mean(error3D))\n",
    "print('Floor detection rate: \\t\\t%2.2lf %%' % ((float(fdetect) / error3D.shape[0])*100))\n",
    "\n",
    "#if cused.size > 0:\n",
    "#    print('cused %.2lf' % np.mean(cused))\n",
    "\n",
    "print('\\n time  %.2lf s' % tsum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 145.57333333   45.56916667    3.7       ]\n",
      " [  98.28722222   40.22122222    7.4       ]\n",
      " [ 130.085        69.78038889    3.7       ]\n",
      " ..., \n",
      " [ 110.26111111   41.78327778   11.1       ]\n",
      " [  70.44572222   39.31894444   11.1       ]\n",
      " [ 146.22666667   44.07372222    3.7       ]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def write_original_positions(positions, filepath):   \n",
    "    with open(filepath, 'wb') as fp:\n",
    "        pickle.dump(positions, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions = np.column_stack((timestamp_test, phoneID_test, y_test[:,0],y_test[:,1]))\n",
    "\n",
    "positions = positions[positions[:,0].argsort()]\n",
    "\n",
    "write_original_positions(positions, path_to_database + \"/positions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.9500872 ,  6.81008594,  4.25747046, ...,  5.7555927 ,\n",
       "        7.92508566,  7.71527629])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
