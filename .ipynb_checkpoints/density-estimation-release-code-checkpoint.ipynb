{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, pearsonr, linregress\n",
    "import copy\n",
    "from importlib import reload\n",
    "import dens_estimation as de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = []\n",
    "with open(\"2015-07-05.json\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "json_lines = []\n",
    "\n",
    "for line in data:\n",
    "    jsline = json.loads(line)\n",
    "    json_lines.append(jsline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame.from_dict(json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rebuild dataframe\n",
    "# make dataframe of dicts nested in 'value' column\n",
    "value = pd.DataFrame(list(frame['value']))\n",
    "del frame['value']\n",
    "\n",
    "# make dataframe of dicts nested in 'trackeeHistory' column\n",
    "trackee = pd.DataFrame(list(value['trackeeHistory']))\n",
    "del value['trackeeHistory']\n",
    "\n",
    "chi2PerDof = pd.DataFrame(list(trackee['chi2PerDof']))\n",
    "chi2PerDof.columns = ['chi2PerDof']\n",
    "probChi2 = pd.DataFrame(list(trackee['probChi2']))\n",
    "probChi2.columns = ['probChi2']\n",
    "nMeasurements = pd.DataFrame(list(trackee['nMeasurements']))\n",
    "nMeasurements.columns = ['nMeasurements']\n",
    "localMac = pd.DataFrame(list(trackee['localMac']))\n",
    "localMac.columns = ['localMac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make dataframe with a 'coordinates' column\n",
    "averagecoordinate = pd.DataFrame(list(value['averagecoordinate']))\n",
    "coordinates = pd.DataFrame(list(averagecoordinate['avg']))\n",
    "averagecoordinate = averagecoordinate.join(coordinates)\n",
    "error = pd.DataFrame(list(averagecoordinate['error']))\n",
    "errorcoordinates = pd.DataFrame(list(error['coordinates']))\n",
    "del errorcoordinates[2]\n",
    "errorcoordinates.columns = ['x_error','y_error']\n",
    "\n",
    "del averagecoordinate['avg']\n",
    "del value['averagecoordinate']\n",
    "\n",
    "# join dataframes\n",
    "frame = frame.join(value.join(averagecoordinate))\n",
    "frame = frame.join(chi2PerDof)\n",
    "frame = frame.join(probChi2)\n",
    "frame = frame.join(errorcoordinates)\n",
    "frame = frame.join(localMac)\n",
    "frame = frame.join(nMeasurements)\n",
    "del frame['regionsNodesIds']\n",
    "del frame['error']\n",
    "del frame['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = frame.sort_values(by='measurementTimestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove randomized MAC-addresses\n",
    "frame = frame[frame['localMac'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove MAC addresses that were still present after 12 pm\n",
    "# list of unique MACs after 12 pm\n",
    "MACafter12 = frame[frame['measurementTimestamp'] > 1436090400000].sourceMac.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# measurements before 6 am\n",
    "framebefore6 = frame[frame['measurementTimestamp'] < 1436068800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = framebefore6['sourceMac'].isin(MACafter12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = framebefore6[np.logical_not(mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of MACs filtered out:', len(framebefore6.sourceMac.unique()) - len(frame.sourceMac.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Data frame contains measurements until 06:00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectWindow(k,start_time):\n",
    "    start = start_time + k * timestep\n",
    "    stop = start + interval\n",
    "\n",
    "    window = df[(df['measurementTimestamp'] >= start) & \n",
    "                       (df['measurementTimestamp'] < stop)]\n",
    "\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataStructures(window):\n",
    "    grids = np.zeros((len(set(window['sourceMac'])), height,width))\n",
    "\n",
    "    # dictionary of histograms (with mac addresses as keys)\n",
    "    histos = dict(zip(set(window['sourceMac']), grids))\n",
    "    \n",
    "    emptylist = [[] for i in range(len(set(window['sourceMac'])))]\n",
    "    positions = dict(zip(set(window['sourceMac']), emptylist))\n",
    "    emptylist = [[] for i in range(len(set(window['sourceMac'])))]\n",
    "    x_errors = dict(zip(set(window['sourceMac']), emptylist))\n",
    "    emptylist = [[] for i in range(len(set(window['sourceMac'])))]\n",
    "    y_errors = dict(zip(set(window['sourceMac']), emptylist))\n",
    "    \n",
    "    history = dict(zip(set(window['sourceMac']), np.zeros(len(set(window['sourceMac'])))))\n",
    "    \n",
    "    return histos, positions, x_errors, y_errors, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resetDataStructures(histos):\n",
    "    \n",
    "    histos_old = copy.deepcopy(histos)\n",
    "    \n",
    "    grids = np.zeros((len(histos), height,width))\n",
    "    histos = dict(zip(histos.keys(), grids))\n",
    "    \n",
    "    emptylist = [[] for i in range(len(histos))]\n",
    "    positions = dict(zip(histos.keys(), emptylist))\n",
    "    emptylist = [[] for i in range(len(histos))]\n",
    "    x_errors = dict(zip(histos.keys(), emptylist))\n",
    "    emptylist = [[] for i in range(len(histos))]\n",
    "    y_errors = dict(zip(histos.keys(), emptylist))\n",
    "    \n",
    "    return histos, histos_old, positions, x_errors, y_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateDataStructures(window, histos, positions, x_errors, y_errors, history):\n",
    "    for i in range(len(window)):\n",
    "        if not window['sourceMac'].values[i] in positions:\n",
    "            histos[window['sourceMac'].values[i]] = np.zeros((height,width))\n",
    "            positions[window['sourceMac'].values[i]] = []\n",
    "            x_errors[window['sourceMac'].values[i]] = []\n",
    "            y_errors[window['sourceMac'].values[i]] = []\n",
    "            history[window['sourceMac'].values[i]] = 0\n",
    "            \n",
    "        positions[window['sourceMac'].values[i]].append(window['coordinates'].values[i][:2])\n",
    "        x_errors[window['sourceMac'].values[i]].append(window['x_error'].values[i])\n",
    "        y_errors[window['sourceMac'].values[i]].append(window['y_error'].values[i])\n",
    "        \n",
    "    return histos, positions, x_errors, y_errors, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createDensityEstimates(window, gridpoints, histos, positions, x_errors, y_errors):\n",
    "\n",
    "    for mac in histos.keys():\n",
    "        if len(positions[mac]) > 0:\n",
    "            values = np.transpose(np.array(positions[mac]))\n",
    "            uncertainties = np.array([x_errors[mac], y_errors[mac]])\n",
    "            kernel = de.variable_kde(values, uncertainties)\n",
    "            binvals = kernel(gridpoints)\n",
    "            # reshape() stacks row-wise, so we use the Fortran-like index ordering\n",
    "            estimate = np.reshape(binvals, (height,width), order='F')\n",
    "            histos[mac] += estimate # * cellsize**2\n",
    "            # re-normalize the evaluation grid to unity when we evaluate whole ArenA\n",
    "            '''\n",
    "            if histos[mac].sum() > 0:\n",
    "                histos[mac] /= histos[mac].sum()\n",
    "            '''\n",
    "    return histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memorizeNonUpdatedEstimates(histos, histos_old, positions, history, memory):\n",
    "    for mac in histos.keys():\n",
    "        if len(positions[mac]) == 0:\n",
    "            if history[mac] < memory:\n",
    "                histos[mac] += histos_old[mac]\n",
    "                history[mac] += 1\n",
    "            else:\n",
    "                history[mac] = 0\n",
    "    return histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sumHistograms(histos):\n",
    "    # total density histogram per period\n",
    "    total_dens_histo = np.zeros((height, width))\n",
    "    \n",
    "    for mac in histos.keys():\n",
    "        total_dens_histo += histos[mac]\n",
    "                \n",
    "    return total_dens_histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runDataAnalysis():\n",
    "    \n",
    "    for k in range(periods):\n",
    "        window = selectWindow(k,start_time)\n",
    "        if k < 1:\n",
    "            histos, positions, x_errors, y_errors, history = createDataStructures(window)\n",
    "            histos, positions, x_errors, y_errors, history =\\\n",
    "            updateDataStructures(window, histos, positions, x_errors, y_errors, history)\n",
    "            histos = createDensityEstimates(window, gridpoints, histos, positions, x_errors, y_errors)\n",
    "        else:\n",
    "            histos, histos_old, positions, x_errors, y_errors = resetDataStructures(histos)\n",
    "            histos, positions, x_errors, y_errors, history =\\\n",
    "            updateDataStructures(window, histos, positions, x_errors, y_errors, history)\n",
    "            histos = createDensityEstimates(window, gridpoints, histos, positions, x_errors, y_errors)\n",
    "            histos = memorizeNonUpdatedEstimates(histos, histos_old, positions, history, memory)\n",
    "\n",
    "        total_dens_histo = sumHistograms(histos)\n",
    "        if k == (periods - 1):\n",
    "            return total_dens_histo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(de)\n",
    "\n",
    "memory_parameter_set = [0]\n",
    "interval_parameter_set = [40000] \n",
    "binsize_parameter_set = [1,] \n",
    "\n",
    "#### movie 1 #############\n",
    "# 1: 05:31:09\n",
    "#timepoint = 1436067069000\n",
    "# 2: 05:32:04 +2:00 UTC\n",
    "#timepoint = 1436067124000\n",
    "# 3: 05:32:39\n",
    "#timepoint = 1436067159000\n",
    "#### movie 2 #############\n",
    "# 4: 05:43:44\n",
    "#timepoint = 1436067824000\n",
    "\n",
    "timepoints = {1: 1436067069000,\n",
    "             2: 1436067124000,\n",
    "             3: 1436067159000,\n",
    "             4: 1436067824000}\n",
    "\n",
    "xsize = 15; ysize = 15\n",
    "x1= 39\n",
    "x2 = x1 + xsize\n",
    "y1 = -39\n",
    "y2 = y1 + ysize\n",
    "\n",
    "for datapointNr in range(1,len(timepoints) + 1):\n",
    "    timepoint = timepoints[datapointNr]\n",
    "    for bins in binsize_parameter_set:\n",
    "        # cellsize is the spatial discretization step size for computing the integral\n",
    "        # bin size should be an integer multiple of cellsize\n",
    "        cellsize = xsize/bins / 25\n",
    "\n",
    "        width = int(xsize / cellsize)\n",
    "        height = int(ysize / cellsize)\n",
    "\n",
    "        X, Y = np.mgrid[x1:x2:cellsize,y1:y2:cellsize]\n",
    "        X = X + cellsize/2\n",
    "        Y = Y + cellsize/2\n",
    "        # note: ravel() concatenates columns\n",
    "        gridpoints = np.vstack([X.ravel(), Y.ravel()])\n",
    "        for m in memory_parameter_set:\n",
    "            memory = m\n",
    "            for t_int in interval_parameter_set:\n",
    "                periods = m + 1\n",
    "                timestep = t_int # 30000\n",
    "                interval = t_int\n",
    "                start_time = timepoint - periods * interval\n",
    "                df = frame[frame['measurementTimestamp'] > start_time]\n",
    "                wifi_estimate = runDataAnalysis()\n",
    "                # create indefinite integral\n",
    "                crowd_estimate = wifi_estimate * cellsize**2\n",
    "                # create histogram\n",
    "                wifi_histo = np.zeros((bins,bins))\n",
    "                # b = divisor variable \n",
    "                b = int(xsize/cellsize / bins)\n",
    "                # integrate / summing over bin intervals\n",
    "                for i in range(bins):\n",
    "                    for j in range(bins):\n",
    "                        wifi_histo[i,j] += crowd_estimate[(i*b):((i+1)*b),(j*b):((j+1)*b)].sum()\n",
    "                # write result to file\n",
    "                filename = str('wifi_histo_%d_%d_%d_%dx%d.csv' % \n",
    "                           (datapointNr, memory, interval, bins, bins))\n",
    "                np.savetxt(filename, wifi_histo, delimiter=',')\n",
    "                print('Output written to', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The code below can be run without running the parameter scan code above if we declare some variables first,\n",
    "    that would otherwise already have been declared. Make sure the CSV files are in the same directory as the \n",
    "    IPynb notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "memory_parameter_set = [0]\n",
    "interval_parameter_set = [40000] \n",
    "binsize_parameter_set = [1,]\n",
    "\n",
    "bins = binsize_parameter_set[0]\n",
    "\n",
    "#### movie 1 #############\n",
    "# 1: 05:31:09\n",
    "#timepoint = 1436067069000\n",
    "# 2: 05:32:04 +2:00 UTC\n",
    "#timepoint = 1436067124000\n",
    "# 3: 05:32:39\n",
    "#timepoint = 1436067159000\n",
    "#### movie 2 #############\n",
    "# 4: 05:43:44\n",
    "#timepoint = 1436067824000\n",
    "\n",
    "timepoints = {1: 1436067069000,\n",
    "             2: 1436067124000,\n",
    "             3: 1436067159000,\n",
    "             4: 1436067824000}\n",
    "\n",
    "xsize = 15; ysize = 15\n",
    "x1= 39\n",
    "x2 = x1 + xsize\n",
    "y1 = -39\n",
    "y2 = y1 + ysize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter scan code above is written for a 3-dimensional parameter scan on 4 time points.\n",
    "However, it was only used for different values of the time interval.\n",
    "The comparison code below runs for timeinterval = 40.\n",
    "The code iterates over the 4 time points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video = []\n",
    "wifi = []\n",
    "\n",
    "for datapointNr in range(1,len(timepoints) + 1):\n",
    "    # load the video people count file\n",
    "    heads = np.loadtxt('headcount-locations-%d-man.csv' % datapointNr, delimiter=',')\n",
    "\n",
    "    # first swap columns, then mirror y-coordinates in x-axis \n",
    "    # to be consistent with wi-fi coordinates\n",
    "    heads[:,[0, 1]] = heads[:,[1, 0]]\n",
    "    heads[:,1] = -heads[:,1]\n",
    "\n",
    "    binsize = xsize / bins\n",
    "\n",
    "    video_estimate = np.zeros((bins, bins))\n",
    "    for b in range(len(heads)):\n",
    "        if heads[b][0] > x1 and heads[b][0] < x2 and heads[b][1] > y1 and heads[b][1] < y2:\n",
    "            x = int((heads[b][0] - x1) / binsize)\n",
    "            y = int((heads[b][1] - y1) / binsize)\n",
    "            video_estimate[y][x] += 1\n",
    "    video.append(video_estimate)\n",
    "    for bins in binsize_parameter_set:\n",
    "        for m in memory_parameter_set:\n",
    "            for t_int in interval_parameter_set:\n",
    "                wifi_histo = np.loadtxt('wifi_histo_%d_%d_%d_%dx%d.csv' % \n",
    "                           (datapointNr, m, t_int, bins, bins), delimiter=',')\n",
    "    wifi.append(wifi_histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# multiply wifi estimate with random/non-random factor\n",
    "factor = 1.2\n",
    "wifi = np.array(wifi) * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average densities per m2\n",
    "wifi = np.array(wifi) / xsize**2\n",
    "video = np.array(video) / ysize**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.ravel(video)\n",
    "X = np.ravel(wifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(timepoints)):\n",
    "    print('Video:', round(Y[i],2),'\\t', 'WiFi:', round(X[i],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
