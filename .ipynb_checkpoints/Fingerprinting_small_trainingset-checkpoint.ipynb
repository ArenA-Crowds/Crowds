{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting data from Jaume university with the (adapted) software of the Tampere University of Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2017 Tampere University of Technology (TUT)\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n",
    "# of the Software, and to permit persons to whom the Software is furnished to do\n",
    "# so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# python script to cluster WLAN RSS fingerprint data with affinity projection\n",
    "# method and compute positioning error on test data\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# enter path to directory where data is stored\n",
    "path_to_database = 'F:/ArenaData/Fingerprinting'\n",
    "# choose algorithm 'km' for k-means and 'ap' for affinity propagation\n",
    "method = 'ap' # 'km'\n",
    "\n",
    "\n",
    "def load_data(path_to_data):\n",
    "\n",
    "    # training data\n",
    "    FILE_NAME_TEST_RSS = path_to_data + '/1478167720_9233432_trainingData.csv'\n",
    "    FILE_NAME_TEST_COORDS = path_to_data + '/1478167720_9233432_trainingData.csv'\n",
    "    FILE_NAME_TRAIN_RSS = path_to_data + '/1478167721_0345678_validationData.csv'\n",
    "    FILE_NAME_TRAIN_COORDS = path_to_data + '/1478167721_0345678_validationData.csv'\n",
    "    # read training data\n",
    "    data_train = genfromtxt(FILE_NAME_TRAIN_RSS, delimiter=',')\n",
    "    data_train = data_train[1:,:]\n",
    "    X_train = data_train[:,0:520]\n",
    "    #labels_train = genfromtxt(FILE_NAME_TRAIN_COORDS, delimiter=',')\n",
    "    y_train = data_train[:,520:523]\n",
    "    y_train[:,2]*=3\n",
    "    X_train[X_train==100] = np.nan\n",
    "    phoneID_train = data_train[:,527]\n",
    "    timestamp_train = data_train[:,528]\n",
    "    floors_train = 3*data_train[:, 522]\n",
    "    # test data\n",
    "    # read test data\n",
    "    data_test = genfromtxt(FILE_NAME_TEST_RSS, delimiter=',')\n",
    "    data_test = data_test[1:,:]\n",
    "    #data_test = genfromtxt(FILE_NAME_TEST_COORDS, delimiter=',')\n",
    "    X_test = data_test[:,0:520]\n",
    "    y_test = data_test[:,520:523]\n",
    "    y_test[:,2]*=3\n",
    "    X_test[X_test==100] = np.nan\n",
    "    phoneID_test = data_test[:,527]\n",
    "    timestamp_test = data_test[:,528]\n",
    "    floors_test = 3*data_test[:, 522]        \n",
    "    X_test[X_test==100] = np.nan\n",
    "    return (X_train, y_train, phoneID_train, timestamp_train, floors_train, X_test, y_test,phoneID_test,timestamp_test,floors_test )\n",
    "\n",
    "\n",
    "def distance(a, b):\n",
    "    return np.sqrt(np.sum(np.power(a-b, 2)))\n",
    "\n",
    "\n",
    "def bdist(a, b, sigma, eps, th, lth=-85, div=10):\n",
    "    diff = a - b\n",
    "\n",
    "    proba = 1/(np.sqrt(2*np.pi)*sigma)*np.exp( \\\n",
    "        -np.power(diff, 2)/(2.0*sigma**2))\n",
    "\n",
    "    proba[np.isnan(proba)] = eps\n",
    "    proba[proba < th] = eps\n",
    "    proba = np.log(proba)\n",
    "    if a.ndim == 2:\n",
    "        cost = np.sum(proba, axis=1)\n",
    "    else:\n",
    "        cost = np.sum(proba)\n",
    "\n",
    "    inv = np.zeros(a.shape[0])\n",
    "    for i in range(a.shape[0]):\n",
    "        aa = np.logical_and(~np.isnan(a[i]), np.isnan(b))\n",
    "        bb = np.logical_and(np.isnan(a[i]), ~np.isnan(b))\n",
    "\n",
    "        nfound = np.concatenate((a[i,aa], b[bb]))\n",
    "        for v in nfound[nfound > lth]:\n",
    "            inv[i] += v - lth\n",
    "\n",
    "    inv /= div\n",
    "    cost -= inv\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def cluster_subset_kmeans(clusters, labels, pos, X_test):\n",
    "    d = []\n",
    "    for i,c in enumerate(kmeans.cluster_centers_):\n",
    "        d.append(distance(pos[:2], c[:2]))\n",
    "\n",
    "    center = np.argmin(d)\n",
    "\n",
    "    return (ss[center], cs[center])\n",
    "\n",
    "\n",
    "def cluster_subset_affinityprop(clusters, labels, X_test):\n",
    "    subset = np.zeros(labels.shape[0]).astype(np.bool)\n",
    "\n",
    "    d = bdist(clusters, X_test, 5, 1e-3, 1e-25)\n",
    "    idx = np.argsort(d)[::-1]\n",
    "\n",
    "    cused = 0\n",
    "    for c in idx[:5]:\n",
    "        subset = np.logical_or(subset, c == labels)\n",
    "        cused += 1\n",
    "\n",
    "    return (subset, cused)\n",
    "\n",
    "\n",
    "def bayes_position(X_train, y_train, X_test, N, sigma, eps, th, lth, div, y_test):\n",
    "    diff = X_train - X_test\n",
    "\n",
    "    proba = 1/(np.sqrt(2*np.pi)*sigma)*np.exp( \\\n",
    "        -np.power(diff, 2)/(2.0*sigma**2))\n",
    "\n",
    "    proba[np.isnan(proba)] = eps\n",
    "    proba[proba < th] = eps\n",
    "    proba = np.log(proba)\n",
    "    cost = np.sum(proba, axis=1)\n",
    "\n",
    "    inv = np.zeros(X_train.shape[0])\n",
    "    for i in range(X_train.shape[0]):\n",
    "        a = np.logical_and(~np.isnan(X_train[i]), np.isnan(X_test))\n",
    "        b = np.logical_and(np.isnan(X_train[i]), ~np.isnan(X_test))\n",
    "\n",
    "        nfound = np.concatenate((X_train[i,a], X_test[b]))\n",
    "        for v in nfound[nfound > lth]:\n",
    "            inv[i] += v - lth\n",
    "\n",
    "    inv /= div\n",
    "    cost -= inv\n",
    "\n",
    "    idx = np.argsort(cost)[::-1]\n",
    "\n",
    "    bias = 3\n",
    "    position = np.zeros(3)\n",
    "    N = min(N, y_train.shape[0])\n",
    "    for i in range(N):\n",
    "        weight = N-i\n",
    "        if i == 0:\n",
    "            weight += bias\n",
    "\n",
    "        position += weight*y_train[idx[i]]\n",
    "\n",
    "    position /= N*(N+1)/2+bias\n",
    "\n",
    "    return (np.array(position), np.mean(inv[idx[:20]]))\n",
    "\n",
    "\n",
    "def position_route(method, X_train, y_train, X_test, y_test, clusters, labels,\n",
    "                   N=5, sigma=5, eps=3e-4, th=1e-25, lth=-85, div=10):\n",
    "\n",
    "    error = []\n",
    "    error2D = []\n",
    "    fdetect = 0\n",
    "    y_pred = []\n",
    "    cused = []\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if i >= 0:\n",
    "            if method=='km':\n",
    "                subset, c = cluster_subset_kmeans(clusters, labels, pos, X_test[i])\n",
    "                cused.append(c)\n",
    "            elif method=='ap':\n",
    "                subset, c = cluster_subset_affinityprop(clusters, labels, X_test[i])\n",
    "                cused.append(c)\n",
    "        else:\n",
    "            subset = np.ones(X_train.shape[0]).astype(np.bool)\n",
    "\n",
    "        if method=='km':\n",
    "            pos, q = bayes_position(X_train[subset], y_train[subset], X_test[i], N, sigma,\n",
    "                                    eps, th, lth, div, y_test[i])\n",
    "\n",
    "            if q > 50:\n",
    "                pos, _ = bayes_position(X_train, y_train, X_test[i], N, sigma,\n",
    "                                        eps, th, lth, div, y_test[i])\n",
    "        elif method=='ap':\n",
    "            pos, _ = bayes_position(X_train[subset], y_train[subset], X_test[i], N, sigma,\n",
    "                                    eps, th, lth, div, y_test[i])\n",
    "\n",
    "        pos[2] = floors[np.argmin(np.abs(floors-pos[2]))]\n",
    "\n",
    "        if i >= 0:\n",
    "            y_pred.append(pos)\n",
    "            error.append(distance(y_test[i], y_pred[-1]))\n",
    "            fdetect += y_pred[-1][2] == y_test[i][2]\n",
    "            # 2D error only if floor was detected correctly\n",
    "            if y_pred[-1][2] == y_test[i][2]:\n",
    "                error2D.append(distance(y_test[i,0:2], np.array(y_pred[-1])[0:2]))\n",
    "\n",
    "    return (np.array(y_pred), np.array(error), np.array(error2D), fdetect, np.array(cused))\n",
    "\n",
    "tsum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "X_train, y_train, phoneID_train, timestamp_train, floors_train, X_test, y_test,phoneID_test,timestamp_test,floors_test  = load_data(path_to_database)\n",
    "\n",
    "# prepare data for processing\n",
    "ap_count = X_train.shape[1]\n",
    "floors = np.unique(floors_train)\n",
    "\n",
    "X_ktrain = X_train.copy()\n",
    "y_ktrain = y_train.copy()\n",
    "\n",
    "X_aux = X_ktrain.copy()\n",
    "X_aux[np.isnan(X_aux)] = 0\n",
    "\n",
    "M = X_ktrain.shape[1]\n",
    "corr = np.zeros((M,M))\n",
    "cth = 500\n",
    "keep = np.ones(M).astype(np.bool)\n",
    "for i in range(M):\n",
    "    for j in range(i,M):\n",
    "        if i != j:\n",
    "            diff = np.abs(X_aux[:,i] - X_aux[:,j])\n",
    "            corr[i,j] = corr[j,i] = np.sum(diff)\n",
    "        else:\n",
    "            corr[i,j] = cth\n",
    "\n",
    "    if keep[i] and np.sum(corr[i,:] < cth) > 0:\n",
    "        for p in np.where(corr[i,:] < cth)[0]:\n",
    "            keep[p] = False\n",
    "\n",
    "X_ktrain = X_ktrain[:,keep]\n",
    "X_test = X_test[:,keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if method=='km':\n",
    "    C = 25\n",
    "\n",
    "    kmeans = KMeans(n_clusters=C, n_init=500, n_jobs=2, tol=1e-9)\n",
    "    labels = kmeans.fit_predict(y_ktrain)\n",
    "    clusters = kmeans.cluster_centers_\n",
    "\n",
    "    N = X_ktrain.shape[0]\n",
    "    aux = np.zeros((C,C))\n",
    "    for i in range(N):\n",
    "        dist = np.zeros(N)\n",
    "        for j in range(N):\n",
    "            dist[j] = distance(y_ktrain[i], y_ktrain[j])\n",
    "\n",
    "        idx = np.argsort(dist)\n",
    "\n",
    "        for p in np.where(labels[idx] != labels[i])[0]:\n",
    "            if dist[idx[p]] < 10:\n",
    "                aux[labels[i],labels[idx[p]]] += 1\n",
    "\n",
    "    ss = np.zeros((C,labels.size)).astype(np.bool)\n",
    "    cs = np.zeros(C)\n",
    "    rssl = []\n",
    "    rssc = []\n",
    "    for c in range(C):\n",
    "        aux[c,c] = 1\n",
    "\n",
    "        for i in np.where(aux[c] != 0)[0]:\n",
    "            ss[c] = np.logical_or(ss[c], labels == i)\n",
    "            cs[c] += 1\n",
    "\n",
    "elif method=='ap':\n",
    "    N = X_ktrain.shape[0]\n",
    "    affinity = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        affinity[i,:] = bdist(X_ktrain, X_ktrain[i], 5, 1e-3, 1e-25)\n",
    "\n",
    "    cluster = AffinityPropagation(damping=0.5, affinity='precomputed')\n",
    "    labels = cluster.fit_predict(affinity)\n",
    "    C = np.unique(labels).size\n",
    "    clusters = X_ktrain[cluster.cluster_centers_indices_]\n",
    "\n",
    "else:\n",
    "    print('Unknown method. Please choose either \"km\" or \"ap\".')\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean positioning error 2D: \t13.845 m\n",
      "Mean positioning error 3D: \t13.094 m\n",
      "Floor detection rate: \t\t45.71 %\n",
      "\n",
      " time  176.07 s\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "t = time.clock()\n",
    "# estimate positions for test data\n",
    "y, error3D, error2D, fdetect, cused = position_route(method, X_ktrain,\n",
    "            y_ktrain, X_test, y_test, clusters, labels, N=5, eps=1e-3)\n",
    "tsum += time.clock() - t\n",
    "\n",
    "print('Mean positioning error 2D: \\t%.3lf m' % np.mean(error2D))\n",
    "print('Mean positioning error 3D: \\t%.3lf m' % np.mean(error3D))\n",
    "print('Floor detection rate: \\t\\t%2.2lf %%' % ((float(fdetect) / error3D.shape[0])*100))\n",
    "\n",
    "#if cused.size > 0:\n",
    "#    print('cused %.2lf' % np.mean(cused))\n",
    "\n",
    "print('\\n time  %.2lf s' % tsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the size of the Jaume university terrain (where GPS was recorded) using the GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmax = np.max(y_test[:,0])\n",
    "ymax = np.max(y_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4865016.6877999976"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7300.8189900927246"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmin= np.min(y_test[:,0])\n",
    "ymin = np.min(y_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7691.3383999988437"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4864745.7450159714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270.94278402626514"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymax - ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.51940990611911"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmax-xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def write_original_positions(positions, filepath):   \n",
    "    with open(filepath, 'wb') as fp:\n",
    "        pickle.dump(positions, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We rotate and normalize the coordinate system before writing the GPS positions down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "positions = np.column_stack((timestamp_test*1000, phoneID_test, y_test[:,0] +7600 ,y_test[:,1]-4864700))\n",
    "\n",
    "positions = positions[positions[:,0].argsort()]\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "pos2 = math.cos(alpha)*positions[:,2] - math.sin(alpha)*positions[:,3]\n",
    "positions[:,3] = math.sin(alpha) * positions[:,2] + math.cos(alpha)*positions[:,3] -140\n",
    "positions[:,2] = pos2 +100\n",
    "\n",
    "write_original_positions(positions, path_to_database + \"/positions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.36990892e+12,   1.30000000e+01,  -1.31086933e+02,\n",
       "          2.15896930e+02],\n",
       "       [  1.36990893e+12,   1.30000000e+01,  -1.31086933e+02,\n",
       "          2.15896930e+02],\n",
       "       [  1.36990893e+12,   1.30000000e+01,  -1.31086933e+02,\n",
       "          2.15896930e+02],\n",
       "       ..., \n",
       "       [  1.37173774e+12,   1.80000000e+01,  -3.53219449e+01,\n",
       "          1.88694201e+02],\n",
       "       [  1.37173774e+12,   1.80000000e+01,  -3.53219449e+01,\n",
       "          1.88694201e+02],\n",
       "       [  1.37173774e+12,   1.80000000e+01,  -3.53219449e+01,\n",
       "          1.88694201e+02]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We rotate and normalize  the coordinate system before writing the fitted positions down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions_fitted = np.column_stack((timestamp_test*1000, phoneID_test, y[:,0]+7600,y[:,1]-4864700, error3D))\n",
    "\n",
    "positions_fitted = positions_fitted[positions_fitted[:,0].argsort()]\n",
    "\n",
    "pos2 = math.cos(alpha)*positions_fitted[:,2] - math.sin(alpha)*positions_fitted[:,3]\n",
    "positions_fitted[:,3] = math.sin(alpha) * positions_fitted[:,2] + math.cos(alpha)*positions_fitted[:,3] -140\n",
    "positions_fitted[:,2] = pos2 +100\n",
    "\n",
    "write_original_positions(positions_fitted, path_to_database + \"/positions_fitted.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19937,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 178.00218475,   25.4448169 ,   50.80861595, ...,    9.17984203,\n",
       "          4.27608609,   10.5344373 ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19937,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
